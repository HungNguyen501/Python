{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ner_dataset.csv', encoding= 'unicode_escape')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   Sentence #  47959 non-null    object\n",
      " 1   Word        1048575 non-null  object\n",
      " 2   POS         1048575 non-null  object\n",
      " 3   Tag         1048575 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 32.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        887908\n",
       "B-geo     37644\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "I-per     17251\n",
       "B-per     16990\n",
       "I-org     16784\n",
       "B-gpe     15870\n",
       "I-geo      7414\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Tag\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract mappings required for the neuralÂ network\n",
    "To train a neural network, we will use two mappings as given below. The neural network will only take integers as input. So lets convert all the unique tokens in the corpus to its respective index.\n",
    "- {token} to {token id}: address the row in embeddings matrix for the current token.\n",
    "- {tag} to {tag id}: one-hot ground truth probability distribution vectors for computing the loss at the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def get_dict_map(data, token_or_tag):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set(data['Word'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['Tag'].to_list()))\n",
    "    \n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "    return tok2idx, idx2tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2idx, idx2token = get_dict_map(data, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(data, 'tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Word_idx'] = data['Word'].map(token2idx)\n",
    "data['Tag_idx'] = data['Tag'].map(tag2idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>19201</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>8643</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>35165</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>25211</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>21254</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag  Word_idx  Tag_idx\n",
       "0  Sentence: 1      Thousands  NNS   O     19201        4\n",
       "1          NaN             of   IN   O      8643        4\n",
       "2          NaN  demonstrators  NNS   O     35165        4\n",
       "3          NaN           have  VBP   O     25211        4\n",
       "4          NaN        marched  VBN   O     21254        4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform columns to extract sequential data\n",
    "Next, lets fill NaN in 'sentence #' column using method ffill in fillna. Thereafter groupby on the sentence column to get a list of tokens and tags for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    1000616\n",
       "Word                0\n",
       "POS                 0\n",
       "Tag                 0\n",
       "Word_idx            0\n",
       "Tag_idx             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "      <td>[19201, 8643, 35165, 25211, 21254, 13758, 2395...</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[19799, 17758, 11157, 26784, 3487, 34061, 2097...</td>\n",
       "      <td>[14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
       "      <td>[2232, 16951, 28903, 33429, 16918, 4548, 23212...</td>\n",
       "      <td>[4, 4, 0, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
       "      <td>[PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[32161, 5786, 20445, 33257, 17506, 4080, 714, ...</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
       "      <td>[NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...</td>\n",
       "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...</td>\n",
       "      <td>[34322, 4144, 26239, 18199, 7606, 2983, 19854,...</td>\n",
       "      <td>[5, 4, 4, 9, 6, 4, 0, 4, 5, 4, 14, 4, 14, 4, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                                               Word  \\\n",
       "0      Sentence: 1  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1     Sentence: 10  [Iranian, officials, say, they, expect, to, ge...   \n",
       "2    Sentence: 100  [Helicopter, gunships, Saturday, pounded, mili...   \n",
       "3   Sentence: 1000  [They, left, after, a, tense, hour-long, stand...   \n",
       "4  Sentence: 10000  [U.N., relief, coordinator, Jan, Egeland, said...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  [NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...   \n",
       "1  [JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...   \n",
       "2  [NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...   \n",
       "3     [PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]   \n",
       "4  [NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...   \n",
       "\n",
       "                                                 Tag  \\\n",
       "0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...   \n",
       "1  [B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
       "2  [O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...   \n",
       "3                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4  [B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...   \n",
       "\n",
       "                                            Word_idx  \\\n",
       "0  [19201, 8643, 35165, 25211, 21254, 13758, 2395...   \n",
       "1  [19799, 17758, 11157, 26784, 3487, 34061, 2097...   \n",
       "2  [2232, 16951, 28903, 33429, 16918, 4548, 23212...   \n",
       "3  [32161, 5786, 20445, 33257, 17506, 4080, 714, ...   \n",
       "4  [34322, 4144, 26239, 18199, 7606, 2983, 19854,...   \n",
       "\n",
       "                                             Tag_idx  \n",
       "0  [4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4, ...  \n",
       "1  [14, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,...  \n",
       "2  [4, 4, 0, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 8, ...  \n",
       "3                  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]  \n",
       "4  [5, 4, 4, 9, 6, 4, 0, 4, 5, 4, 14, 4, 14, 4, 4...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "data_group = data_fillna.groupby(['Sentence #'],as_index=False\n",
    "                                )['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))\n",
    "\n",
    "data_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_group.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad sequences and split the dataset into train,Â test\n",
    "Padding: The LSTM layers accept sequences of same length only. Therefore we will want to transform our list of token_sequences ('Word_idx') which is lists of integers into a matrix of shape (token_sequences, max_len). We can use any length as max_len. In this project we will be using length of the longest sequence as max_len. The sequences that are shorter than max_len are padded with a specified value at the end.\n",
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_train_test_val(data_group, data):\n",
    "    n_token = len(list(set(data['Word'].to_list())))\n",
    "    n_tag = len(list(set(data['Tag'].to_list())))\n",
    "    \n",
    "    tokens = data_group['Word_idx'].tolist()\n",
    "    maxlen = max([len(s) for s in tokens])\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n",
    "    \n",
    "    tags = data_group['Tag_idx'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n",
    "    \n",
    "    n_tags = len(tag2idx)\n",
    "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
    "    \n",
    "    \n",
    "    train_tokens, test_tokens, train_tags, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
    "\n",
    "    print(\n",
    "        'train_tokens length:', len(train_tokens),\n",
    "        '\\ntest_tokens length:', len(test_tokens),\n",
    "        '\\ntrain_tags:', len(train_tags),\n",
    "        '\\ntest_tags:', len(test_tags)\n",
    "    )\n",
    "    \n",
    "    return train_tokens, test_tokens, train_tags, test_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tokens length: 43163 \n",
      "test_tokens length: 4796 \n",
      "train_tags: 43163 \n",
      "test_tags: 4796\n"
     ]
    }
   ],
   "source": [
    "train_tokens, test_tokens, train_tags, test_tags = get_pad_train_test_val(data_group, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22977, 11157, 17933, ..., 35170, 35170, 35170],\n",
       "       [14419, 33508,  3748, ..., 35170, 35170, 35170],\n",
       "       [ 7630,  6597, 11461, ..., 35170, 35170, 35170],\n",
       "       ...,\n",
       "       [23197,  6163, 23605, ..., 35170, 35170, 35170],\n",
       "       [25902,   723, 21838, ..., 35170, 35170, 35170],\n",
       "       [ 7630, 34058,  3165, ..., 35170, 35170, 35170]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for token, tag in zip(train_tokens[0], train_tags[0]):\n",
    "#     print('%s\\t%s' % (token, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ModelÂ Layout\n",
    "\n",
    "Lets go through the process of building a neural network model with lstm layers. Please compare the layers brief and model plot given below to get a better understanding of the layers, input and output dimensions. We are building a simple model with 4 layers.\n",
    "\n",
    "- **Layer 1â-âEmbedding layer**Â : We will feed the padded sequences of equal length (104) to the embedding layer. Once the network has been trained, each token will get transformed into a vector of n dimensions. We have chosen the n dimensions to be (64).Â \n",
    "\n",
    "\n",
    "These are the dimensions (?, 104, 64) plotted in the model plot for input layer and embedding layer. TheÂ ? or None in the dimension specifies batches, when it is None orÂ ? the model can take any batch size.\n",
    "\n",
    "- **Layer 2â-âBidirectional LSTM**Â : Bidirectional lstm takes a recurrent layer (e.g. the first LSTM layer) as an argument. This layer takes the output from the previous embedding layer (104, 64). It also allows you to specify the merge mode, that is how the forward and backward outputs should be combined before being passed on to the next layer. The default mode is to concatenate, where the outputs are concatenated together, providing double the number of outputs to the next layer, in our case its 128(64 * 2).\n",
    "\n",
    "\n",
    "The output dimension of the bidirectional lstm layer (?, 104, 128) becomes the input dimension of the next lstm layer.\n",
    "\n",
    "- **Layer 3â-âLSTM Layer**Â :Â An LSTM network is a recurrent neural network that has LSTM cell blocks in place of our standard neural network layers. These cells have various components called the input gate, the forget gate and the output gate.\n",
    "\n",
    "\n",
    "This layer takes the output dimension from the previous bidirectional lstm layer (?, 104, 128) and outputs (?, 104, 256)\n",
    "\n",
    "\n",
    "\n",
    "- **Layer 4â-âTimeDistributed  Layer**Â : We are dealing with Many to Many RNN Architecture where we expect output from every input sequence for example (a1 âb1, a2 âb2â¦ an âbn) where a and b are inputs and outputs of every sequence. The TimeDistributeDense layers allow you to apply Dense(fully-connected) operation across every output over every time-step. If you don't use this, you would only have one final output.\n",
    "\n",
    "\n",
    "\n",
    "This layer take the output dimension of the previous lstm layer (104, 256) and outputs the max sequence length (104) and max tags (17)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# import keras as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  35172 \n",
      "output_dim:  32 \n",
      "input_length:  104 \n",
      "n_tags:  17\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(list(set(data['Word'].to_list())))+1\n",
    "output_dim = 32\n",
    "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n",
    "n_tags = len(tag2idx)\n",
    "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add Embedding layer\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "\n",
    "    # Add bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "\n",
    "    # Add LSTM\n",
    "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "\n",
    "    # Add timeDistributed Layer\n",
    "    model.add(TimeDistributed(Dense(n_tags, activation=\"relu\")))\n",
    "\n",
    "    #Optimiser \n",
    "    # adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 104, 32)           1125504   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 104, 64)           16640     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 104, 32)           12416     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 104, 17)           561       \n",
      "=================================================================\n",
      "Total params: 1,155,121\n",
      "Trainable params: 1,155,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def train_model(X, y, model):\n",
    "    loss = list()\n",
    "    for _ in range(25):\n",
    "        # fit model for one epoch on this sequence\n",
    "        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.2)\n",
    "        loss.append(hist.history['loss'][0])\n",
    "    return loss\n",
    "model_bilstm_lstm = get_bilstm_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 186s 5s/step - loss: 1.0033 - accuracy: 0.9006 - val_loss: 0.3023 - val_accuracy: 0.9679\n",
      "35/35 [==============================] - 197s 6s/step - loss: 0.2985 - accuracy: 0.9677 - val_loss: 0.2721 - val_accuracy: 0.9679\n",
      "35/35 [==============================] - 226s 6s/step - loss: 0.2742 - accuracy: 0.9677 - val_loss: 0.2402 - val_accuracy: 0.9679\n",
      "35/35 [==============================] - 260s 7s/step - loss: 0.2511 - accuracy: 0.9677 - val_loss: 0.2316 - val_accuracy: 0.9679\n",
      "35/35 [==============================] - 286s 8s/step - loss: 0.2347 - accuracy: 0.9677 - val_loss: 0.2137 - val_accuracy: 0.9679\n",
      "35/35 [==============================] - 314s 9s/step - loss: 0.2236 - accuracy: 0.9677 - val_loss: 0.2099 - val_accuracy: 0.9679\n",
      "35/35 [==============================] - 333s 10s/step - loss: 0.2193 - accuracy: 0.9677 - val_loss: 0.2087 - val_accuracy: 0.9679\n",
      "35/35 [==============================] - 352s 10s/step - loss: 0.2139 - accuracy: 0.9678 - val_loss: 0.2050 - val_accuracy: 0.9679\n",
      "35/35 [==============================] - 364s 10s/step - loss: 0.2058 - accuracy: 0.9678 - val_loss: 0.1975 - val_accuracy: 0.9679\n",
      "35/35 [==============================] - 370s 11s/step - loss: 0.2151 - accuracy: 0.9678 - val_loss: 0.2046 - val_accuracy: 0.9679\n",
      "35/35 [==============================] - 376s 11s/step - loss: 0.1995 - accuracy: 0.9678 - val_loss: 0.1955 - val_accuracy: 0.9679\n",
      "35/35 [==============================] - 387s 11s/step - loss: 0.1934 - accuracy: 0.9678 - val_loss: 0.1935 - val_accuracy: 0.9679\n",
      "35/35 [==============================] - 397s 11s/step - loss: 0.1885 - accuracy: 0.9678 - val_loss: 0.1903 - val_accuracy: 0.9680\n",
      "35/35 [==============================] - 406s 12s/step - loss: 0.1826 - accuracy: 0.9679 - val_loss: 0.1740 - val_accuracy: 0.9680\n",
      "35/35 [==============================] - 412s 12s/step - loss: 0.1526 - accuracy: 0.9680 - val_loss: 0.1492 - val_accuracy: 0.9680\n",
      "35/35 [==============================] - 6278s 184s/step - loss: 0.1412 - accuracy: 0.9681 - val_loss: 0.1436 - val_accuracy: 0.9681\n",
      "35/35 [==============================] - 445s 13s/step - loss: 0.1383 - accuracy: 0.9682 - val_loss: 0.1428 - val_accuracy: 0.9681\n",
      "35/35 [==============================] - 436s 12s/step - loss: 0.1370 - accuracy: 0.9682 - val_loss: 0.1446 - val_accuracy: 0.9681\n",
      "35/35 [==============================] - 437s 12s/step - loss: 0.1336 - accuracy: 0.9683 - val_loss: 0.1408 - val_accuracy: 0.9682\n",
      "35/35 [==============================] - 438s 13s/step - loss: 0.1303 - accuracy: 0.9684 - val_loss: 0.1432 - val_accuracy: 0.9684\n",
      "35/35 [==============================] - 472s 14s/step - loss: 0.1396 - accuracy: 0.9685 - val_loss: 0.1476 - val_accuracy: 0.9683\n",
      "35/35 [==============================] - 588s 17s/step - loss: 0.2674 - accuracy: 0.9398 - val_loss: 0.1735 - val_accuracy: 0.9682\n",
      "35/35 [==============================] - 454s 13s/step - loss: 0.1807 - accuracy: 0.9682 - val_loss: 0.1853 - val_accuracy: 0.9690\n",
      "35/35 [==============================] - 475s 14s/step - loss: 0.1550 - accuracy: 0.9686 - val_loss: 0.1512 - val_accuracy: 0.9686\n",
      "35/35 [==============================] - 512s 15s/step - loss: 0.1528 - accuracy: 0.9688 - val_loss: 0.1496 - val_accuracy: 0.9689\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(results['with_add_lstm'])\n",
    "plt.xlabel('Epochs');\n",
    "plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bilstm_lstm.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 104, 32)           1125504   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 104, 64)           16640     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 104, 32)           12416     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 104, 17)           561       \n",
      "=================================================================\n",
      "Total params: 1,155,121\n",
      "Trainable params: 1,155,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "model = load_model(\"model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Helicopter gunships Saturday pounded militant hideouts in the Orakzai tribal region , where many Taliban militants are believed to have fled to avoid an earlier military offensive in nearby South Waziristan .'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(data_group.iloc[2][\"Word\"])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = text.split(\" \")\n",
    "len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Helicopter</td>\n",
       "      <td>2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gunships</td>\n",
       "      <td>16951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>28903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pounded</td>\n",
       "      <td>33429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>militant</td>\n",
       "      <td>16918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  word_idx\n",
       "0  Helicopter      2232\n",
       "1    gunships     16951\n",
       "2    Saturday     28903\n",
       "3     pounded     33429\n",
       "4    militant     16918"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"word\":li})\n",
    "df[\"word_idx\"] = df[\"word\"].map(token2idx)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Helicopter</td>\n",
       "      <td>2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gunships</td>\n",
       "      <td>16951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>28903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pounded</td>\n",
       "      <td>33429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>militant</td>\n",
       "      <td>16918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  word_idx\n",
       "0  Helicopter      2232\n",
       "1    gunships     16951\n",
       "2    Saturday     28903\n",
       "3     pounded     33429\n",
       "4    militant     16918"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df[\"word_idx\"] = df[\"word_idx\"].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_word_idx = list(df[\"word_idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_bilstm_lstm.predict(my_word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-org: Taliban\n",
      "B-geo: South\n"
     ]
    }
   ],
   "source": [
    "my_li = [idx2tag[np.argmax(score[i][0])] for i in range(len(score))]\n",
    "\n",
    "for i in range(len(my_li)):\n",
    "    if my_li[i] != \"O\":\n",
    "        print(f\"{my_li[i]}: {li[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-tim: Saturday\n",
      "B-geo: Orakzai\n",
      "B-org: Taliban\n",
      "B-geo: South\n",
      "I-geo: Waziristan\n"
     ]
    }
   ],
   "source": [
    "label_li = list(data_group.iloc[2][\"Tag\"])\n",
    "word_li = list(data_group.iloc[2][\"Word\"])\n",
    "for i in range(len(label_li)):\n",
    "    if label_li[i] != \"O\":\n",
    "        print(f\"{label_li[i]}: {word_li[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
